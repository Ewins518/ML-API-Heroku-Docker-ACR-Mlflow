{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f26e6968",
   "metadata": {},
   "source": [
    "Dans cet atelier nous allons entrainer un modèle machine learning avec Scikit-Learn et puis le déployer en tant que web service local et aussi en tant que web service ACI \"Azure Container Instance\". \n",
    "\n",
    "Les étapes de cet Atelier sont les suivantes: \n",
    "\n",
    "1. entrainer localement un modèle Scikit-learn\n",
    "2. Suivre les expérimentations Scikit-learn avec MLFlow sur Azure Machine Learning \n",
    "3. Enregistrer le modèle sur Azure Machine Learning \n",
    "4. Déployer et tester le modèle en tant que web service local \n",
    "5. Déployer et tester le modèle en tant que web service ACI \"Azure Container Instance\"\n",
    "\n",
    "Tout au long de cet atelier nous allons utiliser Pima Indians Diabetes Database. Pour de plus amples informations sur les colonnes, visitez le lien ci-dessous: \n",
    "\n",
    "https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database\n",
    "\n",
    "Smith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261--265). IEEE Computer Society Press."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f605d080",
   "metadata": {},
   "source": [
    "## 1. L'entrainement du modèle Scikit-Learn "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c4edc1",
   "metadata": {},
   "source": [
    "Assurez vous que vous avez installé anaconda avec une version de python 3.7.*\n",
    "\n",
    "Assurez vous aussi que vous avez Docker installé : https://docs.docker.com/desktop/install/windows-install/ \n",
    "\n",
    "Dans le dossier de l'atelier, installez les dépendances requises: pip install -r requirements.txt \n",
    "\n",
    "* azureml-core==1.39\n",
    "* pandas==1.3.5\n",
    "* scikit-learn==0.24.2\n",
    "* cloudpickle==2.0.0\n",
    "* psutil==5.9.0\n",
    "* mlflow==1.24.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32387f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: azureml-core\r\n",
      "Version: 1.54.0\r\n",
      "Summary: Azure Machine Learning core packages, modules, and classes\r\n",
      "Home-page: https://docs.microsoft.com/python/api/overview/azure/ml/?view=azure-ml-py\r\n",
      "Author: Microsoft Corp\r\n",
      "Author-email: \r\n",
      "License: https://aka.ms/azureml-sdk-license\r\n",
      "Location: /home/ewins/anaconda3/lib/python3.9/site-packages\r\n",
      "Requires: adal, argcomplete, azure-common, azure-core, azure-graphrbac, azure-mgmt-authorization, azure-mgmt-containerregistry, azure-mgmt-keyvault, azure-mgmt-network, azure-mgmt-resource, azure-mgmt-storage, backports.tempfile, contextlib2, docker, humanfriendly, jmespath, jsonpickle, knack, msal, msal-extensions, msrest, msrestazure, ndg-httpsclient, packaging, paramiko, pathspec, pkginfo, PyJWT, pyopenssl, python-dateutil, pytz, requests, SecretStorage, urllib3\r\n",
      "Required-by: azureml-pipeline-core, azureml-sdk, azureml-telemetry, azureml-train-automl-client, azureml-train-core\r\n"
     ]
    }
   ],
   "source": [
    "!pip show azureml-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27ca9426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from azureml.core import Workspace\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e81d276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.1\n"
     ]
    }
   ],
   "source": [
    "print(mlflow.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92c9ae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeca44a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ws = Workspace.from_config() \n",
    "subscription_id = '2c2d1cc7-f0fc-4174-b403-4bdd35238850'\n",
    "resource_group = 'Learn_MLOps'\n",
    "workspace_name = 'MLOps_WS'\n",
    "#workspace_location=\"France Central\"\n",
    "ws = Workspace.create(name = workspace_name,resource_group = resource_group,\n",
    "                             subscription_id = subscription_id,exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9e2c31",
   "metadata": {},
   "source": [
    "#### Mettre en place un URI de Tracking des experimentation MLflow sur Azure\n",
    "\n",
    "Nous indiquons à mlflow que l'URI de tracking est celui de mlflow dans azure ML. Toutefois, le lien de tracking de Mlflow dans azure à la forme suivante:\n",
    "\n",
    "azureml://<region>.api.azureml.ms/mlflow/v1.0/subscriptions/<subscription-id>/resourceGroups/<resource-group>/providers/Microsoft.MachineLearningServices/workspaces/<aml-workspace>?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e677210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b9a9e7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'azureml://francecentral.api.azureml.ms/mlflow/v2.0/subscriptions/2c2d1cc7-f0fc-4174-b403-4bdd35238850/resourceGroups/Learn_MLOps/providers/Microsoft.MachineLearningServices/workspaces/MLOps_WS?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.get_tracking_uri()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31ed4fb",
   "metadata": {},
   "source": [
    "Nous allons créer une expérimentation Mlflow dont le nom est \"diabetes-sklearn\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "746e8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/19 22:37:28 INFO mlflow.tracking.fluent: Experiment with name 'weather-sklearn' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='', creation_time=1700429849236, experiment_id='19647fd0-7c68-46ed-9a22-8862df49f082', last_update_time=None, lifecycle_stage='active', name='weather-sklearn', tags={}>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = 'weather-sklearn'\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd1c714",
   "metadata": {},
   "source": [
    "#### chargement du dataset et traitements necéssaires "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecf63818",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('weather_dataset_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30d49552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96449, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48057c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Timestamp', 'Location', 'Temperature_C', 'Humidity', 'Wind_speed_kmph',\n",
       "       'Wind_bearing_degrees', 'Visibility_km', 'Pressure_millibars',\n",
       "       'Current_weather_condition', 'Future_weather_condition'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "192b9447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 96449 entries, 0 to 96448\n",
      "Data columns (total 10 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Timestamp                  96449 non-null  object \n",
      " 1   Location                   96449 non-null  object \n",
      " 2   Temperature_C              96449 non-null  float64\n",
      " 3   Humidity                   96449 non-null  float64\n",
      " 4   Wind_speed_kmph            96449 non-null  float64\n",
      " 5   Wind_bearing_degrees       96449 non-null  int64  \n",
      " 6   Visibility_km              96449 non-null  float64\n",
      " 7   Pressure_millibars         96449 non-null  float64\n",
      " 8   Current_weather_condition  96449 non-null  int64  \n",
      " 9   Future_weather_condition   96449 non-null  int64  \n",
      "dtypes: float64(5), int64(3), object(2)\n",
      "memory usage: 7.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c30c60c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Location</th>\n",
       "      <th>Temperature_C</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind_speed_kmph</th>\n",
       "      <th>Wind_bearing_degrees</th>\n",
       "      <th>Visibility_km</th>\n",
       "      <th>Pressure_millibars</th>\n",
       "      <th>Current_weather_condition</th>\n",
       "      <th>Future_weather_condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-04-01 04:00:00+02:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>8.755556</td>\n",
       "      <td>0.83</td>\n",
       "      <td>11.0446</td>\n",
       "      <td>259</td>\n",
       "      <td>15.8263</td>\n",
       "      <td>1016.51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-04-01 05:00:00+02:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>9.222222</td>\n",
       "      <td>0.85</td>\n",
       "      <td>13.9587</td>\n",
       "      <td>258</td>\n",
       "      <td>14.9569</td>\n",
       "      <td>1016.66</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-04-01 06:00:00+02:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>7.733333</td>\n",
       "      <td>0.95</td>\n",
       "      <td>12.3648</td>\n",
       "      <td>259</td>\n",
       "      <td>9.9820</td>\n",
       "      <td>1016.72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-04-01 07:00:00+02:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>8.772222</td>\n",
       "      <td>0.89</td>\n",
       "      <td>14.1519</td>\n",
       "      <td>260</td>\n",
       "      <td>9.9820</td>\n",
       "      <td>1016.84</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-04-01 08:00:00+02:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>10.822222</td>\n",
       "      <td>0.82</td>\n",
       "      <td>11.3183</td>\n",
       "      <td>259</td>\n",
       "      <td>9.9820</td>\n",
       "      <td>1017.37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Timestamp                Location  Temperature_C  Humidity  \\\n",
       "0  2006-04-01 04:00:00+02:00  Port of Turku, Finland       8.755556      0.83   \n",
       "1  2006-04-01 05:00:00+02:00  Port of Turku, Finland       9.222222      0.85   \n",
       "2  2006-04-01 06:00:00+02:00  Port of Turku, Finland       7.733333      0.95   \n",
       "3  2006-04-01 07:00:00+02:00  Port of Turku, Finland       8.772222      0.89   \n",
       "4  2006-04-01 08:00:00+02:00  Port of Turku, Finland      10.822222      0.82   \n",
       "\n",
       "   Wind_speed_kmph  Wind_bearing_degrees  Visibility_km  Pressure_millibars  \\\n",
       "0          11.0446                   259        15.8263             1016.51   \n",
       "1          13.9587                   258        14.9569             1016.66   \n",
       "2          12.3648                   259         9.9820             1016.72   \n",
       "3          14.1519                   260         9.9820             1016.84   \n",
       "4          11.3183                   259         9.9820             1017.37   \n",
       "\n",
       "   Current_weather_condition  Future_weather_condition  \n",
       "0                          1                         1  \n",
       "1                          1                         1  \n",
       "2                          1                         1  \n",
       "3                          1                         1  \n",
       "4                          1                         1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ddbcc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['Temperature_C', 'Humidity', 'Wind_speed_kmph', 'Wind_bearing_degrees', 'Visibility_km', 'Pressure_millibars', 'Current_weather_condition']].values\n",
    "y = df['Future_weather_condition'].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ed3ce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the Training dataset into Train and Test set for ML training\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6453be9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "339df259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.14529951, -1.56468002, -0.64169187, ..., -0.31725673,\n",
       "         0.19516031,  0.41651557],\n",
       "       [-0.19886072, -1.61591723, -0.38295596, ...,  1.37284272,\n",
       "         0.21155394,  0.41651557],\n",
       "       [-0.82762267,  0.4848081 , -0.1568534 , ...,  0.91190651,\n",
       "         0.10909373,  0.41651557],\n",
       "       ...,\n",
       "       [-1.6496707 ,  0.58728251, -0.43889886, ..., -1.03170787,\n",
       "         0.24972037, -2.40087065],\n",
       "       [ 1.48424188, -1.92334045,  0.74056394, ..., -0.08678863,\n",
       "         0.14230792,  0.41651557],\n",
       "       [ 2.02101829, -1.35973121,  0.96899744, ...,  0.20513764,\n",
       "         0.07869721,  0.41651557]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0aee00e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (77159, 7)\n",
      "X_test: (19290, 7)\n",
      "Y_train: (77159,)\n",
      "Y_test: (19290,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train:\",X_train.shape)\n",
    "print(\"X_test:\",X_test.shape)\n",
    "print(\"Y_train:\",y_train.shape)\n",
    "print(\"Y_test:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "057cd2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb84ecfd",
   "metadata": {},
   "source": [
    "Au lieu d'appeler a chaque fois une fonction de logging (log_metric, log_artifact, ...) nous allons utiliser la fonction autolog() afin de logger toutes les informations relatives au modèle (metrics, parameters, ...) \n",
    "\n",
    "les frameworks suivants supporte la fonction autolog():\n",
    "\n",
    "    Scikit-learn\n",
    "\n",
    "    TensorFlow and Keras\n",
    "\n",
    "    Gluon\n",
    "\n",
    "    XGBoost\n",
    "\n",
    "    LightGBM\n",
    "\n",
    "    Statsmodels\n",
    "\n",
    "    Spark\n",
    "\n",
    "    Fastai\n",
    "\n",
    "    Pytorch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19c6b933",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f5a9ec63d30>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ewins/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/ewins/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/ewins/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/ewins/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    }
   ],
   "source": [
    "mlflow.sklearn.autolog(max_tuning_runs=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ae734a",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning \n",
    "\n",
    "Nous alons utiliser l'algorithme GridSearchCV pour trouver les meilleurs paramétres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5477c58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [10,20,30], 'max_depth':[2,7,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df7521bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridcv=GridSearchCV(rf_clf,param_grid=param_grid,scoring = ['roc_auc', 'precision', 'recall', 'f1', 'accuracy'],refit = 'roc_auc',cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c23f9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/19 22:49:01 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '29324c38-d59d-4197-9605-28d00b121221', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [2, 7, 10], &#x27;n_estimators&#x27;: [10, 20, 30]},\n",
       "             refit=&#x27;roc_auc&#x27;,\n",
       "             scoring=[&#x27;roc_auc&#x27;, &#x27;precision&#x27;, &#x27;recall&#x27;, &#x27;f1&#x27;, &#x27;accuracy&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [2, 7, 10], &#x27;n_estimators&#x27;: [10, 20, 30]},\n",
       "             refit=&#x27;roc_auc&#x27;,\n",
       "             scoring=[&#x27;roc_auc&#x27;, &#x27;precision&#x27;, &#x27;recall&#x27;, &#x27;f1&#x27;, &#x27;accuracy&#x27;])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': [2, 7, 10], 'n_estimators': [10, 20, 30]},\n",
       "             refit='roc_auc',\n",
       "             scoring=['roc_auc', 'precision', 'recall', 'f1', 'accuracy'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridcv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c32d69",
   "metadata": {},
   "source": [
    "## 2.  L'enregistrement du modèle \n",
    "L'enregistrement du modèle dans le registre de modèles d'Azure Machine Learning a pour but de permettre aux utilisateurs de suivre les modifications apportées au modèle via la gestion des versions du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f419829b",
   "metadata": {},
   "source": [
    "nous allons trouver l'expérimentation à partir du workspace en définant le workspace et le nom de l'expérimentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "871df1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment, Workspace\n",
    "experiment_name = 'weather-sklearn'\n",
    "experiment = Experiment(ws, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "908f6990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: weather-sklearn,\n",
      "Id: 29324c38-d59d-4197-9605-28d00b121221,\n",
      "Type: None,\n",
      "Status: Completed)\n",
      "Run(Experiment: weather-sklearn,\n",
      "Id: 5e7cf57e-de44-4afe-87f7-5059b07e7829,\n",
      "Type: None,\n",
      "Status: Failed)\n"
     ]
    }
   ],
   "source": [
    "# afficher tous les runs \n",
    "for r in experiment.get_runs():\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5cc6bd",
   "metadata": {},
   "source": [
    "Trouver le Run actuel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc096bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = '29324c38-d59d-4197-9605-28d00b121221'\n",
    "run = [r for r in experiment.get_runs() if r.id == run_id][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5091a895",
   "metadata": {},
   "source": [
    "Enregistrer le modèle \n",
    "\n",
    "    model_name: un nom arbitraire pour enregister le modèle \n",
    "    model_path: chemin vers  model.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47672e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = run.register_model(model_name = 'weather_model', model_path = 'best_estimator/model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b207bc48",
   "metadata": {},
   "source": [
    "## 3. la création d'un script de Scoring\n",
    "\n",
    "Le script de scoring généralement appelé score.py est utilisé lors de l'inférence comme point d'entrée du modèle.\n",
    "\n",
    "score.py (voir le dossier de l'atelier) consiste en deux fonctions obligatoires:\n",
    "\n",
    "1. init(): charge le modèle en tant que variable globale\n",
    "2. run(): reçoit les nouvelles données à prédire à travers le paramètre data\n",
    "      * effectue un pré-traitement des nouvelles données (optionnel)\n",
    "      * effectue une prédiction sur les nouvelles données\n",
    "      * effectue un post-traitement sur les prédictions (optionnel)\n",
    "      * renvoie les résultats de la prédiction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ca201f",
   "metadata": {},
   "source": [
    "## 4. Déploiement en local\n",
    "\n",
    "Maintenant nous allons debuger le web service locallement avant de le déployer en production avec ACI \" Azure container Instance\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c2c59c",
   "metadata": {},
   "source": [
    "Récupérez le modèle enregistré en définissant le workspace, le nom du modèle et la version du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "757c0ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "model = Model(ws, 'weather_model', version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b3d9916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"assetId\": \"azureml://locations/francecentral/workspaces/aa1e5275-5e6b-4445-acff-433f66377ce9/environments/weather-env/versions/2\",\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20231030.v1\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"buildContext\": null,\n",
       "        \"enabled\": false,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"weather-env\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"conda-forge\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"python=3.9.13\",\n",
       "                \"pip<=23.2.1\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"mlflow\",\n",
       "                        \"cloudpickle==2.0.0\",\n",
       "                        \"lz4==3.1.3\",\n",
       "                        \"numpy==1.23.5\",\n",
       "                        \"packaging\",\n",
       "                        \"pathlib==1.0.1\",\n",
       "                        \"psutil==5.9.0\",\n",
       "                        \"pyyaml==6.0\",\n",
       "                        \"scikit-learn==1.3.2\",\n",
       "                        \"scipy==1.9.1\",\n",
       "                        \"azureml-defaults\",\n",
       "                        \"applicationinsights\"\n",
       "                    ]\n",
       "                }\n",
       "            ],\n",
       "            \"name\": \"mlflow-env\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": \"2\"\n",
       "}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "env = Environment.from_conda_specification(name='weather-env', file_path=\"./conda.yaml\")\n",
    "env.register(ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900495f8",
   "metadata": {},
   "source": [
    "### Définons la configuration d'inférence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5132101",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "inference_config = InferenceConfig(\n",
    "    environment=env,\n",
    "    source_directory=\".\",\n",
    "    entry_script=\"./score.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a037d7",
   "metadata": {},
   "source": [
    "### Définons la configuration de déploiement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d36c5294",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import LocalWebservice\n",
    "deployment_config = LocalWebservice.deploy_configuration(port=6799)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e40dc7",
   "metadata": {},
   "source": [
    "### Déployons le service localement\n",
    "\n",
    "Avant d'exécuter la cellule ci-dessous, assurez vous que Docker est démarré "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "84cb2426",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model weather_model:1 to /tmp/azureml_ae84fqqy/weather_model/1\n",
      "Generating Docker build context.\n",
      "Package creation Succeeded\n",
      "Logging into Docker registry aa1e52755e6b4445acff433f66377ce9.azurecr.io\n",
      "Logging into Docker registry aa1e52755e6b4445acff433f66377ce9.azurecr.io\n",
      "Building Docker image from Dockerfile...\n",
      "Step 1/5 : FROM aa1e52755e6b4445acff433f66377ce9.azurecr.io/azureml/azureml_b51cc7c611c5465dbbb1f942c06bdac1\n",
      " ---> 3b5a950429c7\n",
      "Step 2/5 : COPY azureml-app /var/azureml-app\n",
      " ---> 08455fffbc69\n",
      "Step 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6IjJjMmQxY2M3LWYwZmMtNDE3NC1iNDAzLTRiZGQzNTIzODg1MCIsInJlc291cmNlR3JvdXBOYW1lIjoibGVhcm5fbWxvcHMiLCJhY2NvdW50TmFtZSI6Im1sb3BzX3dzIiwid29ya3NwYWNlSWQiOiJhYTFlNTI3NS01ZTZiLTQ0NDUtYWNmZi00MzNmNjYzNzdjZTkifSwibW9kZWxzIjp7fSwibW9kZWxzSW5mbyI6e319 | base64 --decode > /var/azureml-app/model_config_map.json\n",
      " ---> Running in 7c476c14e30e\n",
      " ---> 37ee1c6d4585\n",
      "Step 4/5 : RUN mv '/var/azureml-app/tmplpuueaas.py' /var/azureml-app/main.py\n",
      " ---> Running in f7f883100400\n",
      " ---> 5f629c4f4b26\n",
      "Step 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n",
      " ---> Running in 9ac8fb2acb09\n",
      " ---> 970420139512\n",
      "Successfully built 970420139512\n",
      "Successfully tagged weather-prediction-service:latest\n",
      "Container (name:compassionate_bhabha, id:391e7a296714d672804beef69a2070112dab73bf05d4466270ed5c59525ce1d9) cannot be killed.\n",
      "Container has been successfully cleaned up.\n",
      "Image sha256:158b081fc0eb72f5f8a5cf8a303a84a33c802e66d850939de4f9f93481959c35 successfully removed.\n",
      "Starting Docker container...\n",
      "Docker container running.\n"
     ]
    }
   ],
   "source": [
    "service = Model.deploy(\n",
    "    workspace = ws,\n",
    "    name = 'weather-prediction-service',\n",
    "    models = [model],\n",
    "    inference_config = inference_config,\n",
    "    deployment_config = deployment_config,\n",
    "    overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5394eace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking container health...\n",
      "Local webservice is running at http://localhost:6799\n"
     ]
    }
   ],
   "source": [
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1ffbe6",
   "metadata": {},
   "source": [
    "Le fichier model.pkl sera téléchargé à partir d'Azure Machine Learning dans un dossier local temporaire et une image Docker avec les dépendances est créée et enregistrée dans Azure Container Registry (ACR). L'image sera téléchargée d'ACR sur la machine locale et un conteneur Docker exécutant le service Web est construit à partir de l'image localement.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31719137",
   "metadata": {},
   "source": [
    "Pour avoir l'URI de scoring lancez la commande suivante "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6835af5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:6799/score\n"
     ]
    }
   ],
   "source": [
    "print (service.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bf3306",
   "metadata": {},
   "source": [
    "## 5. Testons le service localement \n",
    "\n",
    "Pour tester le service localement, ouvrez le notebook \"Inference_test.ipynb\" et assigner l'URI de scroring à la variable scoring_uri\n",
    "\n",
    "Nous avons envoyé une demande d'inference au scoring_uri avec les données au format JSON. Voici à quoi ressemble input_data :\n",
    "\n",
    "{\"input\": \"[{\\\"Pregnancies\\\":6,\\\"Glucose\\\":148,\\\"BloodPressure\\\":72,\\\"SkinThickness\\\":35,\\\"Insulin\\\":0,\\\"BMI\\\":33.6,\\\"DiabetesPedigreeFunction\\\":0.627,\\\"Age\\\":50}]\"}\n",
    "\n",
    "\n",
    "Voici un exemple de la réponse pour l'inférence sur un seul enregistrement. La valeur de retour contient la probabilité qu'une personne reçoive un diagnostic de diabète.\n",
    "\n",
    "prediction: \"{\\\"proba\\\": [0.4829951216899814]}\"\n",
    "\n",
    "\n",
    "Le format de réponse peut être personnalisé dans la fonction run du fichier score.py."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f11f04c",
   "metadata": {},
   "source": [
    "## 6. Déplyons le service sur ACI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74887529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config()\n",
    "from azureml.core.model import Model\n",
    "model = Model(ws, 'weather_model', version=1)\n",
    "from azureml.core import Environment\n",
    "env = Environment.get(workspace = ws, name = 'weather-env', version = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "715bca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "inference_config = InferenceConfig(\n",
    "    environment=env,\n",
    "    source_directory=\".\",\n",
    "    entry_script=\"./score.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f846f2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=0.1, memory_gb=0.5, auth_enabled=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e89aae58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2023-11-19 23:31:04+01:00 Creating Container Registry if not exists.\n",
      "2023-11-19 23:31:04+01:00 Registering the environment.\n",
      "2023-11-19 23:31:06+01:00 Use the existing image.\n",
      "2023-11-19 23:31:06+01:00 Generating deployment configuration.\n",
      "2023-11-19 23:31:07+01:00 Submitting deployment to compute.\n",
      "2023-11-19 23:31:11+01:00 Checking the status of deployment weather-prediction-service..\n",
      "2023-11-19 23:32:43+01:00 Checking the status of inference endpoint weather-prediction-service.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "service = Model.deploy(\n",
    "    workspace = ws,\n",
    "    name = 'weather-prediction-service',\n",
    "    models = [model],\n",
    "    inference_config = inference_config,\n",
    "    deployment_config = deployment_config,\n",
    "    overwrite=True)\n",
    "    \n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5340d97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "74f4969b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://a1ed98f6-478c-4825-91b0-bd37c3eb6cea.francecentral.azurecontainer.io/score\n"
     ]
    }
   ],
   "source": [
    "print (service.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc3b4d8",
   "metadata": {},
   "source": [
    "### Testons le service \n",
    "\n",
    "Refaites la même chose en ouvrant le notebook \"Inference_test.ipynb\" et assigner le nouveau URI de scroring à la variable scoring_uri "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47662441",
   "metadata": {},
   "source": [
    "## Déploiement sur AKS \"Azure Kubernetes Service\" \n",
    "\n",
    "ACI est recommandé pour les tests sur une petite charge de travail de production. Pour une charge de travail importante azure fourni AKS \"Azure Kubernetes Service\"\n",
    "\n",
    "Malheureusement le Déploiement sur AKS n'est pas pris en compte  avec notre sousription actuelle. \n",
    "\n",
    "Néanmoins, je vous ai fourni le code de déploiement pour une éventuelle utilisation future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d6dbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AksWebservice\n",
    "deployment_config = AksWebservice.deploy_configuration(cpu_cores=1, memory_gb=1, auth_enabled=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfef4bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ça suppose la création d'un kubernetes cluster \n",
    "from azureml.core.compute import AksCompute\n",
    "aks_target = AksCompute(ws,\"myaks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc54497d",
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Model.deploy(\n",
    "    workspace = ws,\n",
    "    name = 'diabetes-prediction-service-aks',\n",
    "    models = [model],\n",
    "    inference_config = inference_config,\n",
    "    deployment_config = deployment_config,\n",
    "    deployment_target=aks_target,\n",
    "    overwrite=True)\n",
    "    \n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3b3b44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
